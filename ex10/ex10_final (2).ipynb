{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56caf05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import re    \n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Masking, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b675a834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수: 197463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "      <th>cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78957</th>\n",
       "      <td>I don't need that anymore.</td>\n",
       "      <td>Je n'en ai plus besoin.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106147</th>\n",
       "      <td>Tom drank a lot more than me.</td>\n",
       "      <td>Tom a bu beaucoup plus que moi.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172633</th>\n",
       "      <td>Why can't you take things just as they are?</td>\n",
       "      <td>Pourquoi ne peux-tu pas accepter les choses ju...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63007</th>\n",
       "      <td>He got tired of reading.</td>\n",
       "      <td>Il commence à en avoir assez de lire.</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189419</th>\n",
       "      <td>Have you noticed a change in the size or color...</td>\n",
       "      <td>Avez-vous remarqué un changement de taille ou ...</td>\n",
       "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      eng  \\\n",
       "78957                          I don't need that anymore.   \n",
       "106147                      Tom drank a lot more than me.   \n",
       "172633        Why can't you take things just as they are?   \n",
       "63007                            He got tired of reading.   \n",
       "189419  Have you noticed a change in the size or color...   \n",
       "\n",
       "                                                      fra  \\\n",
       "78957                             Je n'en ai plus besoin.   \n",
       "106147                    Tom a bu beaucoup plus que moi.   \n",
       "172633  Pourquoi ne peux-tu pas accepter les choses ju...   \n",
       "63007               Il commence à en avoir assez de lire.   \n",
       "189419  Avez-vous remarqué un changement de taille ou ...   \n",
       "\n",
       "                                                       cc  \n",
       "78957   CC-BY 2.0 (France) Attribution: tatoeba.org #2...  \n",
       "106147  CC-BY 2.0 (France) Attribution: tatoeba.org #6...  \n",
       "172633  CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "63007   CC-BY 2.0 (France) Attribution: tatoeba.org #3...  \n",
       "189419  CC-BY 2.0 (France) Attribution: tatoeba.org #9...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_path = os.getenv('HOME')+'/aiffel/translator_seq2seq/data/fra.txt'\n",
    "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
    "print('전체 샘플의 수:', len(lines))\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783db559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92214</th>\n",
       "      <td>Who's making the decisions?</td>\n",
       "      <td>Qui prend les décisions ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82515</th>\n",
       "      <td>The company is in the red.</td>\n",
       "      <td>L'entreprise est dans le rouge.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76215</th>\n",
       "      <td>Where exactly did you go?</td>\n",
       "      <td>Où es-tu allée, exactement ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61985</th>\n",
       "      <td>A hyphen is needed here.</td>\n",
       "      <td>Il faut un trait d'union ici.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79045</th>\n",
       "      <td>I enjoyed the party a lot.</td>\n",
       "      <td>J'ai beaucoup apprécié la fête.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               eng                              fra\n",
       "92214  Who's making the decisions?        Qui prend les décisions ?\n",
       "82515   The company is in the red.  L'entreprise est dans le rouge.\n",
       "76215    Where exactly did you go?     Où es-tu allée, exactement ?\n",
       "61985     A hyphen is needed here.    Il faut un trait d'union ici.\n",
       "79045   I enjoyed the party a lot.  J'ai beaucoup apprécié la fête."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = lines[['eng', 'fra']][60000:93000]\n",
    "lines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd2dd4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Those are your choices.', 'Those are your options.',\n",
       "       'Those are your options.', ..., 'Are you coming to the party?',\n",
       "       'Are you coming to the party?', 'Are you done with the paper?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_np_eng= lines['eng'].to_numpy()\n",
    "lines_np_fra= lines['fra'].to_numpy()\n",
    "lines_np_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a049e",
   "metadata": {},
   "source": [
    "# 데이터 전처리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bed3f4",
   "metadata": {},
   "source": [
    "구두점 분리/ 소문자로 변경하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00cb4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos_token = '<start> '\n",
    "eos_token = ' <end>'\n",
    "\n",
    "def preprocess_line(line, plus_token = True):\n",
    "    \n",
    "    line = line.lower().strip() #1\n",
    "    line = re.sub(r\"([?.!,¿])\", r\" \\1 \", line) #2\n",
    "    line = re.sub(r'[\" \"]+', \" \", line) #3\n",
    "    line = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", line) #4\n",
    "\n",
    "    line = line.strip()\n",
    "    \n",
    "    if plus_token == True:\n",
    "        line = sos_token + line + eos_token\n",
    "    \n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd2a509",
   "metadata": {},
   "source": [
    "*1 소문자로 바꾸고, 양쪽 공백을 지운다\n",
    "*2 특수문자 양옆에 공백을 넣는다\n",
    "*3 여러개의 공백은 하나의 공백으로 바꾼다\n",
    "*4 a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꾼다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073fa4b",
   "metadata": {},
   "source": [
    "띄어쓰기 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "990185db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=7000,  # 7000 단어를 기억할 수 있는 토크나이저 만들기\n",
    "        filters=' ',   # 이미 문장을 정제했으니 필터 노필요!\n",
    "        oov_token=\"<unk>\"  # 7000단어에 포함되지 못한 단어는 <unk>으로 바꿈\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)  # corpus를 이용해 토크나이저 내부의 단어장을 완성\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # 토크나이저를 이용해 corpus를 tensor로 변환\n",
    "\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a52127",
   "metadata": {},
   "source": [
    "> tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7e231b",
   "metadata": {},
   "source": [
    "# 영어랑 프랑스어 따로 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24bc33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_lines = []\n",
    "fra_lines = []\n",
    "\n",
    "# eng_lines.append(lines.eng.apply(lambda x : preprocess_line(x,plus_token = False)))\n",
    "# fra_lines.append(lines.fra.apply(lambda x : preprocess_line(x),))\n",
    "\n",
    "for eng, fra in zip(lines.eng, lines.fra):\n",
    "    if len(eng) == 0: continue\n",
    "    if len(fra) == 0: continue   \n",
    "        \n",
    "    eng_lines.append(preprocess_line(eng, plus_token = False))\n",
    "    fra_lines.append(preprocess_line(fra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca8afe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(eng_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07eb2bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 1155, 175, 1274, 4, 3],\n",
       " [2, 1064, 22, 61, 42, 1274, 4, 3],\n",
       " [2, 21, 61, 175, 1274, 4, 3],\n",
       " [2, 21, 61, 42, 1274, 4, 3],\n",
       " [2, 178, 672, 36, 480, 98, 4, 3],\n",
       " [2, 178, 316, 27, 14, 61, 9, 44, 4, 3],\n",
       " [2, 33, 59, 30, 126, 2309, 378, 4, 3],\n",
       " [2, 178, 897, 61, 2646, 4, 3],\n",
       " [2, 17, 89, 8, 24, 3799, 316, 4, 3],\n",
       " [2, 33, 8, 499, 47, 44, 4, 3]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_tensor, eng_tokenizer = tokenize(eng_lines)\n",
    "fra_tensor, fra_tokenizer = tokenize(fra_lines)\n",
    "fra_tensor[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a216de4d",
   "metadata": {},
   "source": [
    "# input & target 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88a5c1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = eng_tensor\n",
    "# 종료 토큰 제거\n",
    "decoder_input = [[char for char in line if char != fra_tokenizer.word_index['<end>']] for line in fra_tensor]\n",
    "# 시작 토큰 제거\n",
    "decoder_target =[[char for char in line if char != fra_tokenizer.word_index['<start>']] for line in fra_tensor]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb3359e",
   "metadata": {},
   "source": [
    "> 이때, 디코더의 입력으로 사용할 시퀀스는 < eos >토큰이 필요가 없고, 디코더의 출력과 비교할 시퀀스는 < sos >가 필요가 없기 때문입니다. 가령, 영어로 'I am a person'이라는 문장을 프랑스어 'Je suis une personne'로 번역하는 번역기를 만든다고 해봅시다. 훈련 과정에서 디코더는 '< sos > Je suis une personne'를 입력받아서 'Je suis une personne < eos >'를 예측하도록 훈련되므로, 이런 방식으로 생성된 두가지 버전의 시퀀스를 준비해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9a9cbd",
   "metadata": {},
   "source": [
    "# padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b80e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 단어장의 크기 : 5975\n",
      "프랑스어 단어장의 크기 : 8501\n"
     ]
    }
   ],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af1fa4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 시퀀스의 최대 길이 31\n",
      "프랑스어 시퀀스의 최대 길이 91\n"
     ]
    }
   ],
   "source": [
    "max_eng_seq_len = max([len(line) for line in eng_lines])\n",
    "max_fra_seq_len = max([len(line) for line in fra_lines])\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14feeace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 31)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 91)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 91)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_sequences(encoder_input, maxlen = max_eng_seq_len, padding='post')\n",
    "decoder_input = pad_sequences(decoder_input, maxlen = max_fra_seq_len, padding='post')\n",
    "decoder_target = pad_sequences(decoder_target, maxlen = max_fra_seq_len, padding='post')\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9180a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(tensor):\n",
    "    total_data_text = list(tensor)\n",
    "    num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "    max_tokens = max(num_tokens)\n",
    "#     max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "    maxlen = int(max_tokens)\n",
    "    tensor = pad_sequences(tensor, padding='post', maxlen=maxlen)  \n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186a397b",
   "metadata": {},
   "source": [
    "> 이것도 패딩을 뒤말고 앞으로 할 수 있나??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75740688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 데이터의 크기(shape) : (33000, 10)\n",
      "프랑스어 입력데이터의 크기(shape) : (33000, 17)\n",
      "프랑스어 출력데이터의 크기(shape) : (33000, 17)\n"
     ]
    }
   ],
   "source": [
    "encoder_input = pad_tensor(encoder_input)\n",
    "decoder_input = pad_tensor(decoder_input)\n",
    "decoder_target = pad_tensor(decoder_target)\n",
    "print('영어 데이터의 크기(shape) :',np.shape(encoder_input))\n",
    "print('프랑스어 입력데이터의 크기(shape) :',np.shape(decoder_input))\n",
    "print('프랑스어 출력데이터의 크기(shape) :',np.shape(decoder_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f6bd06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab_size = len(eng_tokenizer.word_index)+1\n",
    "fra_vocab_size = len(fra_tokenizer.word_index)+1\n",
    "\n",
    "max_eng_seq_len = encoder_input.shape[1]\n",
    "max_fra_seq_len = decoder_input.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55a79f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플의 수 : 33000\n",
      "영어 단어장의 크기 : 5975\n",
      "프랑스어 단어장의 크기 : 8501\n",
      "영어 시퀀스의 최대 길이 10\n",
      "프랑스어 시퀀스의 최대 길이 17\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플의 수 :',len(lines))\n",
    "print('영어 단어장의 크기 :', eng_vocab_size)\n",
    "print('프랑스어 단어장의 크기 :', fra_vocab_size)\n",
    "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
    "print('프랑스어 시퀀스의 최대 길이', max_fra_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955edea",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "854954b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65a5dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 10)\n",
      "(30000, 17)\n",
      "(30000, 17)\n",
      "(3000, 10)\n",
      "(3000, 17)\n",
      "(3000, 17)\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 3000\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print(encoder_input_train.shape)\n",
    "print(decoder_input_train.shape)\n",
    "print(decoder_target_train.shape)\n",
    "print(encoder_input_test.shape)\n",
    "print(decoder_input_test.shape)\n",
    "print(decoder_target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bafbb8e",
   "metadata": {},
   "source": [
    "# Embedding layer 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a142c",
   "metadata": {},
   "source": [
    "인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e0b4294",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 512\n",
    "hidden_size = 512\n",
    "# 인코더에서 사용할 임베딩 층 사용 예시\n",
    "encoder_inputs = Input(shape=(None, ), name='encoder_input')\n",
    "enc_emb =  Embedding(eng_vocab_size, embedding_size,\n",
    "                    input_length=max_eng_seq_len)(encoder_inputs)\n",
    "enc_masking = Masking(mask_value=0.0)(enc_emb)\n",
    "encoder_lstm = LSTM(hidden_size, dropout = 0.5, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_masking)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc31a471",
   "metadata": {},
   "source": [
    "디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5559fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, ), name='decoder_input')\n",
    "dec_emb =  Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "dec_masking = Masking(mask_value=0.0)(dec_emb)\n",
    "decoder_lstm = LSTM(hidden_size, dropout = 0.5, return_sequences = True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_masking, initial_state = encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a3e7185",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67cced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d5d9174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 512)    3059200     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 512)    4352512     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 512)    0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 512)    0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 512), (None, 2099200     masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     masking_1[0][0]                  \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8501)   4361013     lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 15,971,125\n",
      "Trainable params: 15,971,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04ff39b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 49s 21ms/step - loss: 2.0039 - val_loss: 1.6603\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.5168 - val_loss: 1.4231\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.3157 - val_loss: 1.2837\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 17s 18ms/step - loss: 1.1754 - val_loss: 1.1921\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 1.0692 - val_loss: 1.1252\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.9805 - val_loss: 1.0843\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.9125 - val_loss: 1.0521\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.8597 - val_loss: 1.0298\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.8193 - val_loss: 1.0286\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7932 - val_loss: 1.0264\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7662 - val_loss: 1.0254\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.7406 - val_loss: 1.0259\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.7174 - val_loss: 1.0179\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6994 - val_loss: 1.0258\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6885 - val_loss: 1.0242\n",
      "Epoch 16/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6798 - val_loss: 1.0293\n",
      "Epoch 17/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6683 - val_loss: 1.0299\n",
      "Epoch 18/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6582 - val_loss: 1.0275\n",
      "Epoch 19/20\n",
      "938/938 [==============================] - 17s 19ms/step - loss: 0.6455 - val_loss: 1.0255\n",
      "Epoch 20/20\n",
      "938/938 [==============================] - 18s 19ms/step - loss: 0.6338 - val_loss: 1.0159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb0bd5cd0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input_train, decoder_input_train], \n",
    "          y=decoder_target_train, \n",
    "          validation_data = ([encoder_input_test, decoder_input_test], \n",
    "                             decoder_target_test),\n",
    "          batch_size=32, \n",
    "          epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fdd98",
   "metadata": {},
   "source": [
    "# 모델 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780b15e",
   "metadata": {},
   "source": [
    "인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16d2e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, None, 512)         3059200   \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  [(None, 512), (None, 512) 2099200   \n",
      "=================================================================\n",
      "Total params: 5,158,400\n",
      "Trainable params: 5,158,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model = Model(inputs = encoder_inputs, outputs = encoder_states)\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8d4fb",
   "metadata": {},
   "source": [
    "디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a22db1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(embedding_size,)) # 이전 timestep의 hidden state를 저장하는 텐서\n",
    "decoder_state_input_c = Input(shape=(embedding_size,)) # 이전 타입스텝의 cell state를 저장하는 텐서\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c] # 이젠 타입스텝의 히든 스테이트와 셀스테이트를 하나의 변수에 저장\n",
    "\n",
    "dec_emb2 = Embedding(fra_vocab_size, embedding_size)(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state = decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_outputs2) # 디코더의 출력층 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e12109df",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng2idx = eng_tokenizer.word_index\n",
    "fra2idx = fra_tokenizer.word_index\n",
    "idx2eng = eng_tokenizer.index_word\n",
    "idx2fra = fra_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9dbc3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "> 단어에서 정수로, 정수에서 단어로 바꾸는 사전(dictionary)를 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07bc20ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "decoder_input (InputLayer)      [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 512)    4352512     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  2099200     embedding_2[0][0]                \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 8501)   4361013     lstm_1[1][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,812,725\n",
      "Trainable params: 10,812,725\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs2] + decoder_states2)\n",
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "929ae438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # <start>에 해당하는 원-핫 벡터 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = fra2idx['<start>']\n",
    "    \n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "\n",
    "    # stop_condition이 True가 될 때까지 루프 반복\n",
    "    while not stop_condition:\n",
    "        # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # 예측 결과를 문자로 변환\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = idx2fra[sampled_token_index]\n",
    "\n",
    "        # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "        decoded_sentence += ' '+sampled_char\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_char == '<end>' or\n",
    "           len(decoded_sentence) > max_fra_seq_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd3c53",
   "metadata": {},
   "source": [
    "> 예측과정을 위한 함수 decode_sequence()를 구현. decode_sequence()의 입력으로 들어가는 것은 번역하고자 하는 문장의 정수 시퀀스입니다. decode_sequence() 내부에는 인코더를 구현한 encoder_model이 있어서 이 모델에 번역하고자 하는 문장의 정수 시퀀스인 'input_seq'를 입력하면, encoder_model은 마지막 시점의 hidden state를 리턴합니다. 이 hidden state는 디코더의 첫번째 시점의 hidden state가 되고, 디코더는 이제 번역 문장을 완성하기 위한 예측 과정을 진행합니다. 디코더의 예측 과정에서는 이전 시점에서 예측한 단어를 디코더의 현재 시점의 입력으로 넣어주는 작업을 진행합니다. 그리고 이 작업은 종료를 의미하는 종료 토큰을 만나거나, 주어진 최대 길이를 넘을 때까지 반복합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a9d9f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2src(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            temp = temp + idx2eng[i]+' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11723a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2tar(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=fra2idx['<start>']) and i!=fra2idx['<end>']):\n",
    "            temp = temp + idx2fra[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131af256",
   "metadata": {},
   "source": [
    "# 모델평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10ac7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "입력 문장: i really enjoyed myself . \n",
      "정답 문장: je me suis vraiment bien amus . \n",
      "번역기가 번역한 문장:  j me vraiment vraimen\n",
      "-----------------------------------\n",
      "입력 문장: the rent is due tomorrow . \n",
      "정답 문장: le loyer est d pour demain . \n",
      "번역기가 번역한 문장:  le est le demain demai\n",
      "-----------------------------------\n",
      "입력 문장: don t forget to wear a tie . \n",
      "정답 문장: n oubliez pas de porter une cravate . \n",
      "번역기가 번역한 문장:  n pas pas de d . \n",
      "-----------------------------------\n",
      "입력 문장: everyone looked surprised . \n",
      "정답 문장: tout le monde a eu l air surpris . \n",
      "번역기가 번역한 문장:  tout le a a cela \n",
      "-----------------------------------\n",
      "입력 문장: do you want that warmed up ? \n",
      "정답 문장: veux tu que je r chauffe cela ? \n",
      "번역기가 번역한 문장:  voulez vous que qu\n"
     ]
    }
   ],
   "source": [
    "for seq_index in [1,201,501,1004,2015]:\n",
    "    input_seq = encoder_input_test[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print(35 * \"-\")\n",
    "    print('입력 문장:', seq2src(encoder_input_test[seq_index]))\n",
    "    print('정답 문장:', seq2tar(decoder_input_test[seq_index]))\n",
    "    print('번역기가 번역한 문장:', decoded_sentence[:len(decoded_sentence)-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
